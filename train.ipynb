{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/enwik8', 'rb') as f:\n",
    "    data_all = f.read()\n",
    "\n",
    "split = int(len(data_all) * 0.9)\n",
    "data_train = data_all[:split]\n",
    "data_test = data_all[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ftm import prep\n",
    "\n",
    "def train_iter(batch=4, seqlen=2048):\n",
    "    data = [data_train]\n",
    "    data = prep.frombytes(data)\n",
    "    data = prep.chop(data, seqlen=seqlen*16)\n",
    "    data = prep.shuffle(data, bufsize=128)\n",
    "    data = prep.stack(data, batch=batch)\n",
    "    data = prep.chop(data, seqlen=seqlen, dim=1)\n",
    "    data = prep.shuffle(data, bufsize=128)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ftm.model import ModelArgs, Decformer\n",
    "\n",
    "device = torch.device('cuda')\n",
    "dtype = torch.bfloat16\n",
    "\n",
    "decays = 0.5 ** (0.3 ** torch.arange(5))\n",
    "config = ModelArgs(\n",
    "    n_layers = 6,\n",
    "    n_tokens = 256,\n",
    "    n_embed = 1024,\n",
    "\n",
    "    n_mem_dim = 2,\n",
    "    n_mem_key = 256,\n",
    "    n_mem_val = 256,\n",
    "\n",
    "    n_mlp = 2048,\n",
    "    decays = decays.tolist(),\n",
    "    dropout = 0.1,\n",
    ")\n",
    "\n",
    "model = Decformer(config)\n",
    "\n",
    "model.to(dtype).to(device)\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load('./model.pt'))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "params = sum(p.numel() for p in model.parameters())\n",
    "print(f'{params=:,}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
